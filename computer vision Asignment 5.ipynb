{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0047bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "It's basically the physical and logical design which refers to the software, hardware, protocols and the media of transmission of data. Simply put, it refers to how computers are organized and how tasks are allocated among these computers. The two types of widely used network architectures are peer-to-peer aka P2P and client/server aka tiered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa915234",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN is inspired by the biological neural network. For simplicity, in computer science, it is represented as a set of layers. These layers are categorized into three classes which are input, hidden, and output. Knowing the number of input and output layers and number of their neurons is the easiest part. Every network has a single input and output layers. The number of neurons in the input layer equals the number of input variables in the data being processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcabf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Several different types of activation functions are used in Deep Learning. Some of them are explained below: Step Function is one of the simplest kind of activation functions. In this, we consider a threshold value and if the value of net input say y is greater than the threshold then the neuron is activated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f8d32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature Scaling: Having feature with such difference in scale will create issues during the gradient descent process (to be explained later), as can be seen in the contour lines below ...\n",
    "Batch normalization: Normalize the input data is good to improve the speed of training, as the picture above (picture 1), this is another way to fix the skewed problem in ...\n",
    "Training and Gradient descent. Rather than just talk about gradient descent, I wanted to go quickly to the whole training process to give context to the gradient descent optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1cbf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "A LearningRateSchedule that uses an exponential decay schedule. When training a model, it is often useful to lower the learning rate as the training progresses. This schedule applies an exponential decay function to an optimizer step, given a provided initial learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ac0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mini-batch sizes, commonly called “batch sizes” for brevity, are often tuned to an aspect of the computational architecture on which the implementation is being executed. Such as a power of two that fits the memory requirements of the GPU or CPU hardware like 32, 64, 128, 256, and so on. Batch size is a slider on the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6608cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimization refers to a procedure for finding the input parameters or arguments to a function that result in the minimum or maximum output of the function. The most common type of optimization problems encountered in machine learning are continuous function optimization, where the input arguments to the function are real-valued numeric values, e.g. floating point values. The output from the function is also a real-valued evaluation of the input value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d1129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training a neural network takes a considerable amount of time, even with the current technology. In the model-building phase, if we set the number of epochs too low, then the training will stop even before the model converges. Conversely, if we set the number of epochs too high, we’ll face overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a56187",
   "metadata": {},
   "outputs": [],
   "source": [
    "Regularization is the most popular technique to prevent overfitting. It is a group of methods that forces the learning algorithms to make a model simpler. Applying the regularization technique may slightly increase the bias but slightly reduces the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2 Normalization. It may be defined as the normalization technique that modifies the dataset values in a way that in each row the sum of the squares will always be up to 1. It is also called least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ab9d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntroduction to Data Augmentation. The prediction accuracy of the Supervised Deep Learning models is largely reliant on...\n",
    "Numerical Data Augmentation. The augmentation techniques used in deep learning applications depends on the type of the...\n",
    "Image Augmentation for Computer Vision Applications. Amongst the popular deep learning applications, computer vision..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd394b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2a0de4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
