{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ad164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "C onvolutional neural networks (CNN) are one of the principal components of neural networks. It consists of neurons with learning weights and prejudices. Each neuron receives multiple inputs and takes a weighted sum over them where it transmits an activation function and responds with an output again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e18817",
   "metadata": {},
   "outputs": [],
   "source": [
    "Understanding the feed-forward mechanism is required in order to create a neural network that solves difficult practical problems such as predicting the result of a football game or the movement of a stock price. An artificial neural network models biological synapses and neurons and can be used to make predictions for complex data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3772a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=(3, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4))\n",
    "model.compile(loss='mean_squared_error', optimizer='SGD')\n",
    "\n",
    "x = np.array([[[1, 2], [3, 4], [5, 6]]])\n",
    "\n",
    "y = model.predict(x)\n",
    "\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe2e2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "The image shape is (N, H, W, C) and we want the output to have shape (N, C, H, W). Therefore we need to apply tf.transpose with a well chosen permutation perm\n",
    "N: number of images in the batch\n",
    "H: height of the image\n",
    "W: width of the image\n",
    "C: number of channels of the image (ex: 3 for RGB, 1 for grayscale...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09670ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Here is a visualization: Left: A regular 3-layer Neural Network. Right: A ConvNet arranges its neurons in three dimensions (width, height, depth), as visualized in one of the layers. Every layer of a ConvNet transforms the 3D input volume to a 3D output volume of neuron activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d7baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "A general definition that spans different types of neurons across sensory modalities could be expressed as follows. The receptive field is a portion of sensory space that can elicit neuronal responses when stimulated. The sensory space can be defined in a single dimension (e.g. carbon chain length of an odorant), two dimensions (e.g. skin surface) or multiple dimensions (e.g. space, time and tuning properties of a visual receptive field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de248b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stride specifies how much we move the convolution filter at each step. By default the value is 1, as you can see in the figure below. We can have bigger strides if we want less overlap between the receptive fields. This also makes the resulting feature map smaller since we are skipping over potential locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54098ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB Images has three colour channels. A batch of 128 grayscale images of size 256 × 256 could thus be stored in a tensor of shape (128, 256, 256, 1), and a batch of 128 color images could be stored in a tensor of shape (128, 256, 256, 3) Video data is one of the few types of real-world data for which you’ll need 5D tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fd1e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "In image processing, a convolution requires three components: 1 An input image. 2 A kernel matrix that we are going to apply to the input image. 3 An output image to store the output of the input image convolved with the kerne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a2cf13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
